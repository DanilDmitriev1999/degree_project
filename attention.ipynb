{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "attention.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tbQXdS3BzQ4c",
        "colab_type": "text"
      },
      "source": [
        "# Техническая часть"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1ylpFUlyyuSy",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        },
        "outputId": "c73219b0-3261-428f-e606-0f19815cc7ac"
      },
      "source": [
        "#!pip3 -qq install torch==0.4.1\n",
        "#!pip -qq install torchtext==0.3.1\n",
        "\n",
        "#!pip -qq install spacy==2.0.16\n",
        "#!python -m spacy download en\n",
        "!pip install sacremoses==0.0.5\n",
        "#!pip install subword_nmt==0.3.5\n",
        "!wget -qq http://www.manythings.org/anki/rus-eng.zip \n",
        "!unzip rus-eng.zip"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Archive:  rus-eng.zip\n",
            "  inflating: rus.txt                 \n",
            "  inflating: _about.txt              \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KCkx8VJ_2B2w",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "import math\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "\n",
        "\n",
        "if torch.cuda.is_available():\n",
        "    from torch.cuda import FloatTensor, LongTensor\n",
        "    DEVICE = torch.device('cuda')\n",
        "else:\n",
        "    from torch import FloatTensor, LongTensor\n",
        "    DEVICE = torch.device('cpu')\n",
        "\n",
        "np.random.seed(42)\n",
        "\n",
        "import warnings\n",
        "\n",
        "warnings.filterwarnings('ignore')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9tbBtWte2Lp2",
        "colab_type": "text"
      },
      "source": [
        "## Подготовка данных"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OzQsGEL92I31",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 207
        },
        "outputId": "68e3de1a-7439-4d32-a05f-18a25a0db8e0"
      },
      "source": [
        "!shuf -n 10 rus.txt"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "I'd love to see inside Tom's house.\tМне бы хотелось увидеть дом Тома изнутри.\tCC-BY 2.0 (France) Attribution: tatoeba.org #1096181 (CK) & #7021710 (odexed)\n",
            "I wasn't complaining.\tЯ не жаловался.\tCC-BY 2.0 (France) Attribution: tatoeba.org #5858495 (CK) & #5913976 (marafon)\n",
            "I thought this was important.\tЯ думал, что это важно.\tCC-BY 2.0 (France) Attribution: tatoeba.org #2543229 (CK) & #3514060 (odexed)\n",
            "I drink tea, too.\tЯ тоже пью чай.\tCC-BY 2.0 (France) Attribution: tatoeba.org #3378130 (CK) & #4874433 (venticello)\n",
            "I had trouble parking.\tУ меня были проблемы с парковкой.\tCC-BY 2.0 (France) Attribution: tatoeba.org #7878163 (CK) & #7893655 (marafon)\n",
            "It's in your bag.\tОно в Вашей сумке.\tCC-BY 2.0 (France) Attribution: tatoeba.org #5790191 (Eccles17) & #5791193 (marafon)\n",
            "Tom was perfect.\tТом был безупречен.\tCC-BY 2.0 (France) Attribution: tatoeba.org #4471306 (Hybrid) & #5797112 (marafon)\n",
            "I'll just check.\tЯ только проверю.\tCC-BY 2.0 (France) Attribution: tatoeba.org #2247765 (CK) & #2607161 (Olya)\n",
            "I've started learning French.\tЯ начал учить французский.\tCC-BY 2.0 (France) Attribution: tatoeba.org #2451528 (CK) & #2522716 (paul_lingvo)\n",
            "Are you sure that Tom wants to do that?\tТы уверена, что Том хочет это сделать?\tCC-BY 2.0 (France) Attribution: tatoeba.org #6978132 (CK) & #7002812 (odexed)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MoERPtpK2PLz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import spacy\n",
        "from torchtext.data import Field, Example, Dataset, BucketIterator\n",
        "\n",
        "spacy_en = spacy.load('en')\n",
        "BOS_TOKEN = '<s>'\n",
        "EOS_TOKEN = '</s>'\n",
        "\n",
        "source_field = Field(tokenize='spacy', init_token=None, eos_token=EOS_TOKEN, lower=True)\n",
        "target_field = Field(tokenize='moses', init_token=BOS_TOKEN, eos_token=EOS_TOKEN, lower=True)\n",
        "fields = [('source', source_field), ('target', target_field)]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zttOAtfP2VjC",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "05a0b1f0-eecf-45ac-9e73-4f12b872f87e"
      },
      "source": [
        "from tqdm import tqdm\n",
        "\n",
        "MAX_TOKENS_COUNT = 16\n",
        "SUBSET_SIZE = .3\n",
        "\n",
        "examples = []\n",
        "with open('rus.txt') as f:\n",
        "    for line in tqdm(f, total=328190):\n",
        "        source_text, target_text, _ = line.split('\\t')\n",
        "        source_text = source_field.preprocess(source_text)\n",
        "        target_text = target_field.preprocess(target_text)\n",
        "        if len(source_text) <= MAX_TOKENS_COUNT and len(target_text) <= MAX_TOKENS_COUNT:\n",
        "            if np.random.rand() < SUBSET_SIZE:\n",
        "                examples.append(Example.fromlist([source_text, target_text], fields))"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "380911it [01:02, 6047.77it/s]\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rmYEgLsZ2lA2",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        },
        "outputId": "d2a5b151-f55d-47c0-bfd8-47f7907f0457"
      },
      "source": [
        "dataset = Dataset(examples, fields)\n",
        "\n",
        "train_dataset, test_dataset = dataset.split(split_ratio=0.85)\n",
        "\n",
        "print('Train size =', len(train_dataset))\n",
        "print('Test size =', len(test_dataset))\n",
        "\n",
        "source_field.build_vocab(train_dataset, min_freq=2)\n",
        "print('Source vocab size =', len(source_field.vocab))\n",
        "\n",
        "target_field.build_vocab(train_dataset, min_freq=2)\n",
        "print('Target vocab size =', len(target_field.vocab))\n",
        "\n",
        "train_iter, test_iter = BucketIterator.splits(\n",
        "    datasets=(train_dataset, test_dataset), batch_sizes=(32, 512), shuffle=True, device=DEVICE, sort=False\n",
        ")"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train size = 96658\n",
            "Test size = 17057\n",
            "Source vocab size = 6681\n",
            "Target vocab size = 15231\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CXssdVK82oND",
        "colab_type": "text"
      },
      "source": [
        "# Seq2seq with Attention"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "65mCOGVK3QNK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "batch = next(iter(train_iter))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FYDkfCZy2nvR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Encoder(nn.Module):\n",
        "    def __init__(self, vocab_size, emb_dim=128, rnn_hidden_dim=256, num_layers=1, bidirectional=False):\n",
        "        super().__init__()\n",
        "\n",
        "        self._emb = nn.Embedding(vocab_size, emb_dim)\n",
        "        self._rnn = nn.GRU(input_size=emb_dim, hidden_size=rnn_hidden_dim, \n",
        "                           num_layers=num_layers, bidirectional=bidirectional)\n",
        "\n",
        "    def forward(self, inputs, hidden=None):\n",
        "        encoder_output, encoder_hidden = self._rnn(self._emb(inputs), hidden)\n",
        "        return encoder_output, encoder_hidden"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oe7w1LEY3Bl3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Decoder(nn.Module):\n",
        "    def __init__(self, vocab_size, emb_dim=128, rnn_hidden_dim=256, attn_dim=128, num_layers=1):\n",
        "        super().__init__()\n",
        "\n",
        "        self._emb = nn.Embedding(vocab_size, emb_dim)\n",
        "        self._attention = DotAttention(rnn_hidden_dim, rnn_hidden_dim, attn_dim)\n",
        "        self._rnn = nn.GRU(input_size=emb_dim + rnn_hidden_dim, \n",
        "                           hidden_size=rnn_hidden_dim, num_layers=num_layers)\n",
        "        self._out = nn.Linear(rnn_hidden_dim, vocab_size)\n",
        "\n",
        "    def forward(self, inputs, encoder_output, encoder_mask, hidden=None):\n",
        "        embs = self._emb(inputs)\n",
        "        outputs, attentions = [], []\n",
        "        key_proj = self._attention._key_layer(encoder_output)\n",
        "        for i in range(embs.shape[0]):\n",
        "            # encoder_output (seq_len, batch_size, rnn_hidden_dim)\n",
        "            # hidden (1, batch_size, rnn_hidden_dim)\n",
        "            context, f_att = self._attention(query=hidden, key_proj=key_proj, \n",
        "                                             value=encoder_output, mask=encoder_mask)\n",
        "            context = context.unsqueeze(0)\n",
        "            rnn_input = torch.cat((embs[i: i+1], context), -1)\n",
        "            output, hidden = self._rnn(rnn_input, hidden)\n",
        "            \n",
        "            outputs.append(output)\n",
        "            attentions.append(f_att)\n",
        "            \n",
        "        output = torch.cat(outputs)\n",
        "        attentions = torch.cat(attentions)\n",
        "        return self._out(output), hidden, attentions"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V_k1Hrsr3EJS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class DotAttention(nn.Module):\n",
        "    def __init__(self, query_size, key_size, hidden_dim):  # query_size == hidden_dim, \n",
        "        # но пусть будет как отдельная переменная, чтобы не переписывать декодер\n",
        "        super().__init__()\n",
        "        \n",
        "        self._key_layer = nn.Linear(key_size, hidden_dim)\n",
        "        \n",
        "    def forward(self, query, key_proj, value, mask):\n",
        "        # key (seq_len, batch_size, rnn_hidden_dim)\n",
        "        # query (1, batch_size, rnn_hidden_dim)\n",
        "        \n",
        "        query = query.permute(1, 2, 0)\n",
        "        key_proj = key_proj.permute(1, 0, 2)\n",
        "        f_att = query.new_zeros([key_proj.shape[0], key_proj.shape[1], query.shape[1]])  # (batch_size, seq_len, 1)\n",
        "        for i in range(key_proj.shape[0]):\n",
        "            f_att[i] = torch.matmul(key_proj[i], query[i])\n",
        "        f_att = f_att.permute(1, 0, 2)\n",
        "        \n",
        "        f_att.data.masked_fill_(mask.unsqueeze(2), -float('inf'))\n",
        "        \n",
        "        # f_att (seq_len, batch_size, 1)\n",
        "        \n",
        "        f_att = F.softmax(f_att, 0)\n",
        "        \n",
        "        scores = f_att * value\n",
        "        \n",
        "        return scores.sum(0), f_att"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Fd559PEc3MlW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class TranslationModel(nn.Module):\n",
        "    def __init__(self, source_vocab_size, target_vocab_size, emb_dim=64, rnn_hidden_dim=128, \n",
        "                 attn_dim=128, num_layers=1, bidirectional_encoder=False):\n",
        "        \n",
        "        super().__init__()\n",
        "        \n",
        "        self.encoder = Encoder(source_vocab_size, emb_dim, rnn_hidden_dim, num_layers, bidirectional_encoder)\n",
        "        self.decoder = Decoder(target_vocab_size, emb_dim, rnn_hidden_dim, attn_dim, num_layers)\n",
        "        \n",
        "    def forward(self, source_inputs, target_inputs):\n",
        "        encoder_mask = source_inputs == 1\n",
        "        encoder_output, encoder_hidden = self.encoder(source_inputs)\n",
        "        \n",
        "        return self.decoder(target_inputs, encoder_output, encoder_mask, encoder_hidden)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fcNj8zGb3c7d",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "3de8e985-c2ac-4b44-9e4c-92d856e05077"
      },
      "source": [
        "model = TranslationModel(source_vocab_size=len(source_field.vocab),\n",
        "                         target_vocab_size=len(target_field.vocab)).to(DEVICE)\n",
        "\n",
        "model(batch.source, batch.target)[0].shape"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([15, 32, 15231])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tCeavRCy354G",
        "colab_type": "text"
      },
      "source": [
        "## Обучение модели"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tFFajW-B3fSv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "tqdm.get_lock().locks = []\n",
        "\n",
        "\n",
        "def do_epoch(model, criterion, data_iter, optimizer=None, name=None):\n",
        "    epoch_loss = 0\n",
        "    \n",
        "    is_train = not optimizer is None\n",
        "    name = name or ''\n",
        "    model.train(is_train)\n",
        "    \n",
        "    batches_count = len(data_iter)\n",
        "    \n",
        "    with torch.autograd.set_grad_enabled(is_train):\n",
        "        with tqdm(total=batches_count) as progress_bar:\n",
        "            for i, batch in enumerate(data_iter):                \n",
        "                logits, _, _ = model(batch.source, batch.target)\n",
        "                \n",
        "                target = torch.cat((batch.target[1:], batch.target.new_ones((1, batch.target.shape[1]))))\n",
        "                loss = criterion(logits.view(-1, logits.shape[-1]), target.view(-1))\n",
        "\n",
        "                epoch_loss += loss.item()\n",
        "\n",
        "                if optimizer:\n",
        "                    optimizer.zero_grad()\n",
        "                    loss.backward()\n",
        "                    nn.utils.clip_grad_norm_(model.parameters(), 1.)\n",
        "                    optimizer.step()\n",
        "\n",
        "                progress_bar.update()\n",
        "                progress_bar.set_description('{:>5s} Loss = {:.5f}, PPX = {:.2f}'.format(name, loss.item(), \n",
        "                                                                                         math.exp(loss.item())))\n",
        "                \n",
        "            progress_bar.set_description('{:>5s} Loss = {:.5f}, PPX = {:.2f}'.format(\n",
        "                name, epoch_loss / batches_count, math.exp(epoch_loss / batches_count))\n",
        "            )\n",
        "            progress_bar.refresh()\n",
        "\n",
        "    return epoch_loss / batches_count\n",
        "\n",
        "\n",
        "def fit(model, criterion, optimizer, train_iter, epochs_count=1, val_iter=None):\n",
        "    best_val_loss = None\n",
        "    all_train_loss = []\n",
        "    all_val_loss = []\n",
        "    for epoch in range(epochs_count):\n",
        "        name_prefix = '[{} / {}] '.format(epoch + 1, epochs_count)\n",
        "        train_loss = do_epoch(model, criterion, train_iter, optimizer, name_prefix + 'Train:')\n",
        "        all_train_loss.append(train_loss)\n",
        "        \n",
        "        if not val_iter is None:\n",
        "            val_loss = do_epoch(model, criterion, val_iter, None, name_prefix + '  Val:')\n",
        "            all_val_loss.append(val_loss)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T0-fpKTS4UeS",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 391
        },
        "outputId": "ea7d7771-9f01-4841-8eaf-f3a8d492ef5c"
      },
      "source": [
        "model = TranslationModel(source_vocab_size=len(source_field.vocab),\n",
        "                         target_vocab_size=len(target_field.vocab)).to(DEVICE)\n",
        "\n",
        "pad_idx = target_field.vocab.stoi['<pad>']\n",
        "criterion = nn.CrossEntropyLoss(ignore_index=pad_idx).to(DEVICE)\n",
        "\n",
        "optimizer = optim.Adam(model.parameters())\n",
        "\n",
        "fit(model, criterion, optimizer, train_iter, epochs_count=11, val_iter=test_iter)"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[1 / 11] Train: Loss = 3.70732, PPX = 40.74: 100%|██████████| 3021/3021 [10:04<00:00,  4.99it/s]\n",
            "[1 / 11]   Val: Loss = 2.83543, PPX = 17.04: 100%|██████████| 34/34 [00:16<00:00,  2.02it/s]\n",
            "[2 / 11] Train: Loss = 2.53668, PPX = 12.64: 100%|██████████| 3021/3021 [10:10<00:00,  4.95it/s]\n",
            "[2 / 11]   Val: Loss = 2.28759, PPX = 9.85: 100%|██████████| 34/34 [00:16<00:00,  2.00it/s]\n",
            "[3 / 11] Train: Loss = 2.02868, PPX = 7.60: 100%|██████████| 3021/3021 [10:14<00:00,  4.91it/s]\n",
            "[3 / 11]   Val: Loss = 2.03288, PPX = 7.64: 100%|██████████| 34/34 [00:17<00:00,  1.97it/s]\n",
            "[4 / 11] Train: Loss = 1.70668, PPX = 5.51: 100%|██████████| 3021/3021 [10:02<00:00,  5.02it/s]\n",
            "[4 / 11]   Val: Loss = 1.86794, PPX = 6.47: 100%|██████████| 34/34 [00:17<00:00,  1.99it/s]\n",
            "[5 / 11] Train: Loss = 1.48033, PPX = 4.39: 100%|██████████| 3021/3021 [10:01<00:00,  5.02it/s]\n",
            "[5 / 11]   Val: Loss = 1.77463, PPX = 5.90: 100%|██████████| 34/34 [00:16<00:00,  2.01it/s]\n",
            "[6 / 11] Train: Loss = 1.31478, PPX = 3.72: 100%|██████████| 3021/3021 [10:09<00:00,  4.96it/s]\n",
            "[6 / 11]   Val: Loss = 1.71651, PPX = 5.57: 100%|██████████| 34/34 [00:16<00:00,  2.03it/s]\n",
            "[7 / 11] Train: Loss = 1.18627, PPX = 3.27: 100%|██████████| 3021/3021 [10:28<00:00,  4.81it/s]\n",
            "[7 / 11]   Val: Loss = 1.67821, PPX = 5.36: 100%|██████████| 34/34 [00:17<00:00,  1.98it/s]\n",
            "[8 / 11] Train: Loss = 1.08564, PPX = 2.96: 100%|██████████| 3021/3021 [10:04<00:00,  5.00it/s]\n",
            "[8 / 11]   Val: Loss = 1.66347, PPX = 5.28: 100%|██████████| 34/34 [00:16<00:00,  2.01it/s]\n",
            "[9 / 11] Train: Loss = 1.00443, PPX = 2.73: 100%|██████████| 3021/3021 [10:27<00:00,  4.82it/s]\n",
            "[9 / 11]   Val: Loss = 1.65849, PPX = 5.25: 100%|██████████| 34/34 [00:17<00:00,  1.99it/s]\n",
            "[10 / 11] Train: Loss = 0.93721, PPX = 2.55: 100%|██████████| 3021/3021 [10:21<00:00,  4.86it/s]\n",
            "[10 / 11]   Val: Loss = 1.64905, PPX = 5.20: 100%|██████████| 34/34 [00:16<00:00,  2.03it/s]\n",
            "[11 / 11] Train: Loss = 0.88226, PPX = 2.42: 100%|██████████| 3021/3021 [10:15<00:00,  4.91it/s]\n",
            "[11 / 11]   Val: Loss = 1.64146, PPX = 5.16: 100%|██████████| 34/34 [00:17<00:00,  2.00it/s]\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xBmShfZLbkDv",
        "colab_type": "text"
      },
      "source": [
        "## Визуализация"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7xUZ_Fz-4aFK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def greedy_decode(model, source_text, source_field, target_field):\n",
        "    bos_index = target_field.vocab.stoi[BOS_TOKEN]\n",
        "    eos_index = target_field.vocab.stoi[EOS_TOKEN]\n",
        "    \n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "        result, attentions = [], []\n",
        "        source = source_field.preprocess(source_text)\n",
        "        inputs = source_field.process([source]).to(DEVICE)\n",
        "        \n",
        "        encoder_output, encoder_hidden = model.encoder(inputs)\n",
        "        encoder_mask = torch.zeros_like(inputs).byte()\n",
        "        \n",
        "        hidden = encoder_hidden\n",
        "        step = LongTensor([[bos_index]])\n",
        "        \n",
        "        for _ in range(50):\n",
        "            step, hidden, attention = model.decoder(step, encoder_output, encoder_mask, hidden)\n",
        "            step = step.argmax(-1)\n",
        "            attentions.append(attention.squeeze(1))\n",
        "          \n",
        "            if step.squeeze().item() == eos_index:\n",
        "                break\n",
        "            \n",
        "            result.append(step.item())   \n",
        "        result = [target_field.vocab.itos[ind] for ind in result]\n",
        "        return source, result, torch.cat(attentions, -1).data.cpu().numpy()\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PWdMdCeZWaZd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "\n",
        "def plot_heatmap(src, trg, scores):\n",
        "\n",
        "    fig, ax = plt.subplots(figsize=(9, 9))\n",
        "    heatmap = ax.pcolor(scores, cmap='OrRd')\n",
        "\n",
        "    ax.set_xticklabels(trg, minor=False)\n",
        "    ax.set_yticklabels(src, minor=False)\n",
        "\n",
        "    ax.xaxis.tick_top()\n",
        "    ax.set_xticks(np.arange(scores.shape[1]) + 0.5, minor=True)\n",
        "    ax.set_yticks(np.arange(scores.shape[0]) + 0.5, minor=False)\n",
        "    ax.invert_yaxis()\n",
        "\n",
        "    plt.colorbar(heatmap)\n",
        "    plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mRhpaT23Wd1Z",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "9dad95c5-7633-43ab-c655-04f75507918d"
      },
      "source": [
        "source, result, attentions = greedy_decode(model, \"Where do you live ?\", source_field, target_field)\n",
        "print(' '.join(result))"
      ],
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "где ты живёшь ?\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CE55wXC3Wfbc",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 543
        },
        "outputId": "d3d80a4e-43e3-4636-816f-01e66ba72aad"
      },
      "source": [
        "plot_heatmap(source + ['</s>'], result + ['</s>'], attentions)"
      ],
      "execution_count": 93,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 648x648 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GP2-Lr6VWfVu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "byEISV_oWfRV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ab7gn-lCWfL-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZDZYb0VlWfGz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fvZRuk68WfCC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "208fRCV2We8p",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g_r-NZ3LWe6L",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}